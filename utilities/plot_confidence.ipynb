{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ancient-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/projects/patho1/melanoma_diagnosis/code/multi-scale_melanoma_diagnosis/')\n",
    "from sklearn.metrics import confusion_matrix as c_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "local-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/projects/patho1/melanoma_diagnosis/results/binarize/4scale_49_512x2x64'\n",
    "results_txt = 'result.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "retired-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path.join(results_dir, results_txt), 'r') as f:\n",
    "    lines = [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "amended-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((4,4), dtype=int)\n",
    "confidence_matrix = {0: {}, 1: {}, 2: {}, 3:{}}\n",
    "confidence_case_matrix = {}\n",
    "case_pred = {}\n",
    "case_target = {}\n",
    "case_lookup = {0: {}, 1: {}, 2: {}, 3:{}}\n",
    "slice_pred = []\n",
    "slice_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efficient-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    line = line.split(',')\n",
    "    im_p = line[0]\n",
    "    pred = int(line[1])\n",
    "    slice_pred.append(pred)\n",
    "#     scores_raw = line[2].split(',')\n",
    "#     scores = [float(scores_raw[i].replace('[', '').replace(']', '')) for i in range(len(scores_raw))]\n",
    "    scores_raw = line[2:2+4]\n",
    "    scores = [float(scores_raw[i].replace('[', '').replace(']', '')) for i in range(len(scores_raw))]\n",
    "    label = max(0, int(path.basename(path.dirname(im_p))) - 2)\n",
    "    slice_label.append(label)\n",
    "    bn = path.basename(im_p)\n",
    "    im_ind = path.splitext(bn)[0]\n",
    "    case = im_ind.split('_x10')[0]\n",
    "    confusion_matrix[label][pred] += 1\n",
    "    if pred not in confidence_matrix[label]:\n",
    "        confidence_matrix[label][pred] = [scores]\n",
    "        case_lookup[label][pred] = [im_ind]\n",
    "    else:\n",
    "        confidence_matrix[label][pred].append(scores)\n",
    "        case_lookup[label][pred].append(im_ind)\n",
    "    if case not in confidence_case_matrix:\n",
    "        confidence_case_matrix[case] = {} \n",
    "        case_pred[case] = pred\n",
    "        case_target[case] = label\n",
    "    else:\n",
    "        if pred > case_pred[case]:\n",
    "            case_pred[case] = pred\n",
    "    confidence_case_matrix[case][str(im_ind[-1])] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "wireless-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_confusion_matrix = np.zeros((4,4))\n",
    "pred_list = []\n",
    "label_list = []\n",
    "for case in case_pred:\n",
    "    pred = case_pred[case]\n",
    "    label = case_target[case]\n",
    "    case_confusion_matrix[label][pred] += 1\n",
    "    pred_list.append(pred)\n",
    "    label_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ordinary-correction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from metrics.cmat_metrics import CMMetrics, CMResults\n",
    "results_summary = dict()\n",
    "results_summary['true_labels'] = [int(x) for x in label_list]\n",
    "results_summary['pred_labels'] = [int(x) for x in pred_list]\n",
    "#print(len(y_true))\n",
    "#print(len(y_pred))\n",
    "cmat = c_matrix(results_summary['true_labels'], results_summary['pred_labels'])\n",
    "cmat_np_arr = np.array(cmat)\n",
    "conf_mat_eval = CMMetrics()\n",
    "cmat_results: CMResults = conf_mat_eval.compute_metrics(conf_mat=cmat_np_arr)\n",
    "cmat_results_dict = cmat_results._asdict()\n",
    "for k, v in cmat_results_dict.items():\n",
    "    if isinstance(v, np.ndarray):\n",
    "        values = v.tolist()\n",
    "    results_summary['{}'.format(k)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "reported-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3873873873524876\n",
      "0.3873873873524876\n",
      "0.795795795771898\n",
      "0.3873873873524876\n"
     ]
    }
   ],
   "source": [
    "print(results_summary['overall_accuracy'])\n",
    "print(results_summary['sensitivity_micro'])\n",
    "print(results_summary['specificity_micro'])\n",
    "print(results_summary['f1_micro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "polish-thanks",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.  3.  0.  3.]\n",
      " [22.  5.  1.  2.]\n",
      " [19.  3.  1.  7.]\n",
      " [ 5.  0.  3. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(case_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "premier-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_filename = path.join(results_dir, 'train_case.csv')\n",
    "fields = ['case ID', 'Prediction', 'Label', 'slice number', '0', '1', '2', '3']\n",
    "with open(csv_filename, 'w') as csv_f:\n",
    "    csvwriter = csv.writer(csv_f)\n",
    "    csvwriter.writerow(fields) \n",
    "    for case in confidence_case_matrix:\n",
    "        row = [case]\n",
    "        row.append(str(case_pred[case]))\n",
    "        row.append(str(case_target[case]))\n",
    "        csvwriter.writerow(row)\n",
    "        for i in confidence_case_matrix[case]:\n",
    "            slice_row = ['', '', '']\n",
    "            slice_row.append(str(i))\n",
    "            for conf in confidence_case_matrix[case][str(i)]:\n",
    "                slice_row.append(str(conf))\n",
    "            csvwriter.writerow(slice_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "for j in range(4):\n",
    "    class_conf = [x[j] for x in confidence_matrix[1][2]]\n",
    "    row = j//2\n",
    "    col = j-2*(j//2)\n",
    "    _ = ax[row][col].hist(class_conf, bins=[0, 0.25, 0.5, 0.75, 1])\n",
    "    ax[row][col].title.set_text('class {}'.format(j))\n",
    "plt.setp(ax, xticks=[0, 0.25, 0.5, 0.75, 1], yticks=range(0, 36, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confidence_case_matrix['MP_0052'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-belief",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
